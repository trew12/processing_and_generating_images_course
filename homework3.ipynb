{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474f03226ba3d28f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:55:06.983972700Z",
     "start_time": "2023-12-03T12:54:42.046177100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import copy\n",
    "from clearml import Task, Logger, TaskTypes\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "from torchmetrics import Precision, Recall, F1Score\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d81e1bd6fcdb8e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:55:16.027651900Z",
     "start_time": "2023-12-03T12:55:15.982661700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'model_name': 'baseline.pth',\n",
    "    'batch_size': 1000,\n",
    "    'num_classes': 10,\n",
    "    'epochs': 25,\n",
    "    'seed': 47,\n",
    "    'string': 'my string',\n",
    "    'aug_params': {\n",
    "        'color_jitter': {'brightness': 0.5, 'contrast': 0.5, 'saturation': 0.5, 'hue': (-0.1, 0.1)}, \n",
    "        'random_flip': {'p': 0.5}\n",
    "    }, \n",
    "    'optimizer_params': {\n",
    "        'lr': 1e-3\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d3bc4d4ccf3fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:55:16.644368700Z",
     "start_time": "2023-12-03T12:55:16.601365400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x221f028cb70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(parameters['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c67d10f74385676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T12:55:22.298592200Z",
     "start_time": "2023-12-03T12:55:18.782854200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [transforms.ColorJitter(**parameters['aug_params']['color_jitter']),\n",
    "     transforms.RandomHorizontalFlip(**parameters['aug_params']['random_flip']), \n",
    "     transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "patch_transforms = transforms.Compose(\n",
    "    [transforms.Resize((33, 33)), \n",
    "     transforms.ToTensor(),]\n",
    ")\n",
    "\n",
    "patch_train_set = CIFAR10(\"./data\", download=True, transform=patch_transforms, train=True)\n",
    "patch_val_set = CIFAR10(\"./data\", download=True, transform=patch_transforms, train=False)\n",
    "train_set = CIFAR10(\"./data\", download=True, transform=train_transforms, train=True)\n",
    "val_set = CIFAR10(\"./data\", download=True, transform=train_transforms, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d7a9e8-f189-41ea-859d-8a43a555e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_set.classes\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d66f961-37e2-4c46-a26c-848cfc7ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(images, labels, predicted_labels=None):\n",
    "    plt.figure(figsize=(20, 10), facecolor='white')\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image = np.transpose(images[i].numpy(), (1, 2, 0)) \n",
    "        plt.imshow(image)\n",
    "        if predicted_labels is not None:\n",
    "            plt.title(f'{classes[labels[i]]} / {classes[predicted_labels[i]]}')\n",
    "        else:\n",
    "            plt.title(classes[labels[i]])\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543883c9-669b-40cf-a8bf-d32cb0dfb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(series, iteration, precision_metric, recall_metric, f1score_metric, loss):\n",
    "        log.report_histogram(\"PrecisionByClass\", series, iteration=iteration, values=precision_metric.cpu())\n",
    "        log.report_histogram(\"RecallByClass\", series, iteration=iteration, values=recall_metric.cpu())\n",
    "        log.report_histogram(\"F1ScoreByClass\", series, iteration=iteration, values=f1score_metric.cpu())\n",
    "        \n",
    "        log.report_scalar(\"Precision\", series, iteration=iteration, value=torch.mean(precision_metric).cpu())\n",
    "        log.report_scalar(\"Recall\", series, iteration=iteration, value=torch.mean(recall_metric).cpu())\n",
    "        log.report_scalar(\"F1Score\", series, iteration=iteration, value=torch.mean(f1score_metric).cpu())\n",
    "        log.report_scalar(\"CrossEntropyLoss\", series, iteration=iteration, value=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9256ea-8c05-4614-8470-18713f833864",
   "metadata": {},
   "source": [
    "### Self-supervised learning backbone pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70cddc0-db24-4eb6-bf8a-df4c65473a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patch_pairs(inputs):\n",
    "    positions = [(dx, dy) for dx in [-1, 0, 1] for dy in [-1, 0, 1] if (dx, dy) != (0, 0)]\n",
    "    \n",
    "    inputs1 = inputs[:, :, 11:22, 11:22]\n",
    "    inputs2 = [] \n",
    "    targets = []\n",
    "    \n",
    "    for i in range(inputs.size(0)):\n",
    "        target = np.random.randint(0, 8)\n",
    "        dx, dy = positions[target]\n",
    "        patch_x = slice(11 + dx * 11, 22 + dx*11)\n",
    "        patch_y = slice(11 + dy * 11, 22 + dy*11)\n",
    "        inputs2.append(inputs[i, :, patch_x, patch_y])\n",
    "        targets.append(target)\n",
    "    inputs2 = torch.stack(inputs2)\n",
    "    inputs1 = F.interpolate(inputs1, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "    inputs2 = F.interpolate(inputs2, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "\n",
    "    \n",
    "    return inputs1, inputs2, torch.tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73efe37-90d6-4f15-bb12-5d96c5f65f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSLModel(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = nn.Linear(960 * 2, 8)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.backbone(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.backbone(x2)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d31a5ec-62af-46ca-8d84-b1f4e7caa9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = Recall(task='multiclass', average=None, num_classes=8).to(device)\n",
    "precision = Precision(task='multiclass', average=None, num_classes=8).to(device)\n",
    "f1score = F1Score(task='multiclass', average=None, num_classes=8).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69ce3865-8867-4c3c-b4c6-756f3d57456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=7f042f2d22e448ea8d4b4d44c1e05deb\n",
      "2024-03-13 16:49:18,730 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "ClearML results page: https://app.clear.ml/projects/c907675c01ad4f69a5f853a34e753129/experiments/7f042f2d22e448ea8d4b4d44c1e05deb/output/log\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name='Processing and generating images course', \n",
    "    task_name='HW3 SSL model training', \n",
    "    task_type=TaskTypes.training)\n",
    "log = Logger.current_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d507518a-aaf8-4c42-9ddc-343460df29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_train_loader = torch.utils.data.DataLoader(patch_train_set, batch_size=parameters['batch_size'])\n",
    "patch_val_loader = torch.utils.data.DataLoader(patch_val_set, batch_size=parameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ef5ee896a87feb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T11:20:28.332874400Z",
     "start_time": "2023-12-01T11:20:27.592946600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "backbone = mobilenet_v3_large(weights=None).features\n",
    "ssl_model = SSLModel(backbone)\n",
    "ssl_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(ssl_model.parameters(), **parameters['optimizer_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aec0850-a2eb-4c87-9905-18d52c495a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [27:04<00:00, 32.50s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(2 * parameters['epochs'])):\n",
    "    train_epoch_loss = 0.0\n",
    "    processed_data = 0\n",
    "    ssl_model.train()\n",
    "    for inputs, _ in patch_train_loader:\n",
    "        inputs1, inputs2, targets = create_patch_pairs(inputs)\n",
    "        inputs1, inputs2, targets = inputs1.to(device), inputs2.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = ssl_model(inputs1, inputs2)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        train_epoch_loss += loss.item()\n",
    "        processed_data += inputs.size(0)\n",
    "        \n",
    "        precision(outputs, targets)\n",
    "        recall(outputs, targets)\n",
    "        f1score(outputs, targets)\n",
    "        \n",
    "    precision_metric = precision.compute()\n",
    "    precision.reset()\n",
    "    recall_metric = recall.compute()\n",
    "    recall.reset()\n",
    "    f1score_metric = f1score.compute()\n",
    "    f1score.reset()\n",
    "    log_metrics(\"Train\", epoch, precision_metric, recall_metric, f1score_metric, train_epoch_loss / processed_data)\n",
    "    \n",
    "    ssl_model.eval()\n",
    "    val_epoch_loss = 0.0\n",
    "    processed_data = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in patch_val_loader:\n",
    "            inputs1, inputs2, targets = create_patch_pairs(inputs)\n",
    "            inputs1, inputs2, targets = inputs1.to(device), inputs2.to(device), targets.to(device)\n",
    "\n",
    "            outputs = ssl_model(inputs1, inputs2)\n",
    "            loss = criterion(outputs, targets)\n",
    "            torch.cuda.empty_cache()\n",
    "            val_epoch_loss += loss.item()\n",
    "            processed_data += inputs.size(0)\n",
    "            \n",
    "            precision(outputs, targets)\n",
    "            recall(outputs, targets)\n",
    "            f1score(outputs, targets)\n",
    "    \n",
    "    precision_metric = precision.compute()\n",
    "    precision.reset()\n",
    "    recall_metric = recall.compute()\n",
    "    recall.reset()\n",
    "    f1score_metric = f1score.compute()\n",
    "    f1score.reset()\n",
    "    log_metrics(\"Validation\", epoch, precision_metric, recall_metric, f1score_metric, train_epoch_loss / processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716c8e99-12b5-41ce-bfd9-375dba39682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-13 17:16:35,900 - clearml.frameworks - INFO - Found existing registered model id=71e36632d9e64a648b5b6f30af434537 [C:\\Users\\Anton Volodin\\PycharmProjects\\processing_and_generating_images_course\\pretrainder_backbone.pth] reusing it.\n"
     ]
    }
   ],
   "source": [
    "torch.save(ssl_model.backbone.state_dict(), 'pretrainder_backbone.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a04fe7-949b-4be7-a1e1-2d0fe3abdf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08801ec0-8664-4b20-a84d-743b76e983ac",
   "metadata": {},
   "source": [
    "### Training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb4a93ce-a388-4684-a7b0-6be12418cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(backbone_weights=None):\n",
    "    model = mobilenet_v3_large(weights=None)\n",
    "    in_features = model.classifier[3].in_features\n",
    "    model.classifier[3] = nn.Linear(in_features, parameters['num_classes'])\n",
    "    if backbone_weights:\n",
    "        model.features.load_state_dict(torch.load(backbone_weights))\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4f2169a11ef954d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T13:34:18.118173100Z",
     "start_time": "2023-12-01T11:20:28.402873300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), **parameters['optimizer_params'])\n",
    "    for epoch in range(parameters['epochs']):\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, targets = data\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss += loss.item()\n",
    "            precision(outputs, targets)\n",
    "            recall(outputs, targets)\n",
    "            f1score(outputs, targets)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "        precision_metric = precision.compute()\n",
    "        precision.reset()\n",
    "        recall_metric = recall.compute()\n",
    "        recall.reset()\n",
    "        f1score_metric = f1score.compute()\n",
    "        f1score.reset()\n",
    "        log_metrics(\"Train\", epoch, precision_metric, recall_metric, f1score_metric, train_epoch_loss / len(train_set))\n",
    "\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for j, data in enumerate(val_loader):\n",
    "                images, targets = data\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                val_epoch_loss += loss.item()\n",
    "                precision(outputs, targets)\n",
    "                recall(outputs, targets)\n",
    "                f1score(outputs, targets)\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "        precision_metric = precision.compute()\n",
    "        precision.reset()\n",
    "        recall_metric = recall.compute()\n",
    "        recall.reset()\n",
    "        f1score_metric = f1score.compute()\n",
    "        f1score.reset()\n",
    "        log_metrics(\"Validation\", epoch, precision_metric, recall_metric, f1score_metric, val_epoch_loss / len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "262d19f8-b9c4-4fc0-a6da-43a350e63332",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = Recall(task='multiclass', average=None, num_classes=parameters['num_classes']).to(device)\n",
    "precision = Precision(task='multiclass', average=None, num_classes=parameters['num_classes']).to(device)\n",
    "f1score = F1Score(task='multiclass', average=None, num_classes=parameters['num_classes']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb922c1-ccac-4a31-9d78-8c3427873fc7",
   "metadata": {},
   "source": [
    "### Exp 1: 100% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ec3d0bf-5f0c-48db-b61b-abbe4efeac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=61b167925a0f4d959b1c5d28566b632d\n",
      "ClearML results page: https://app.clear.ml/projects/c907675c01ad4f69a5f853a34e753129/experiments/61b167925a0f4d959b1c5d28566b632d/output/log\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name='Processing and generating images course', \n",
    "    task_name='HW3 Exp 1 pretrained', \n",
    "    task_type=TaskTypes.training)\n",
    "log = Logger.current_logger()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=parameters['batch_size'])\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=parameters['batch_size'])\n",
    "\n",
    "model = get_model(backbone_weights='pretrainder_backbone.pth')\n",
    "train(model, train_loader, val_loader)\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca176f-a2ab-4cfd-b7ef-9c8bb340c883",
   "metadata": {},
   "source": [
    "### Exp 2: 50% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2acda5a5-a0ee-429e-bc83-eac08019d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_half, _ = random_split(train_set, [len(train_set) // 2, len(train_set) // 2])\n",
    "train_loader = torch.utils.data.DataLoader(train_set_half, batch_size=parameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f6ca087-366f-4263-815c-63b63df4d63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=84698a15ca0d48398bc157c09588fa25\n",
      "ClearML results page: https://app.clear.ml/projects/c907675c01ad4f69a5f853a34e753129/experiments/84698a15ca0d48398bc157c09588fa25/output/log\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name='Processing and generating images course', \n",
    "    task_name='HW3 Exp 2 not pretrained', \n",
    "    task_type=TaskTypes.training)\n",
    "log = Logger.current_logger()\n",
    "model = get_model(backbone_weights=None)\n",
    "train(model, train_loader, val_loader)\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51bbf839-4084-4131-9f62-f30d62986e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=4e0141caee3e4810b149d4386138ab2d\n",
      "ClearML results page: https://app.clear.ml/projects/c907675c01ad4f69a5f853a34e753129/experiments/4e0141caee3e4810b149d4386138ab2d/output/log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task = Task.init(\n",
    "    project_name='Processing and generating images course', \n",
    "    task_name='HW3 Exp 2 pretrained', \n",
    "    task_type=TaskTypes.training)\n",
    "log = Logger.current_logger()\n",
    "model = get_model(backbone_weights='pretrainder_backbone.pth')\n",
    "train(model, train_loader, val_loader)\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb1f07-bc5d-41d7-be02-aaea44a4527c",
   "metadata": {},
   "source": [
    "### Exp 3: 10% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef134b3b-6201-40c2-a27f-93d562587176",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_10, _ = random_split(train_set, [len(train_set) // 10, len(train_set) - len(train_set) // 10 ])\n",
    "train_loader = torch.utils.data.DataLoader(train_set_10, batch_size=parameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2113c535-6c3c-4678-ab8a-e38142c27f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=7e51ea5e9d8447ada915f5c402a363d3\n",
      "ClearML results page: https://app.clear.ml/projects/c907675c01ad4f69a5f853a34e753129/experiments/7e51ea5e9d8447ada915f5c402a363d3/output/log\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name='Processing and generating images course', \n",
    "    task_name='HW3 Exp 3 not pretrained', \n",
    "    task_type=TaskTypes.training)\n",
    "log = Logger.current_logger()\n",
    "\n",
    "\n",
    "model = get_model(backbone_weights=None)\n",
    "train(model, train_loader, val_loader)\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a60e5fa-4a2e-40a9-8152-d03b6c6d0705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=e5fdb4e6ae1c40b1b275295e645b7c8b\n",
      "ClearML results page: https://app.clear.ml/projects/c907675c01ad4f69a5f853a34e753129/experiments/e5fdb4e6ae1c40b1b275295e645b7c8b/output/log\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name='Processing and generating images course', \n",
    "    task_name='HW3 Exp 3 pretrained', \n",
    "    task_type=TaskTypes.training)\n",
    "log = Logger.current_logger()\n",
    "\n",
    "\n",
    "model = get_model(backbone_weights='pretrainder_backbone.pth')\n",
    "train(model, train_loader, val_loader)\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
